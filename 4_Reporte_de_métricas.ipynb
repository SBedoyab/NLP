{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **0. Importación de librerías y carga de datos**"
      ],
      "metadata": {
        "id": "cVxIdE3_tQQA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ## ***Librerías***"
      ],
      "metadata": {
        "id": "TtlUF19ztfUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from joblib import load # Carga de datos\n",
        "from scipy import sparse # Carga de datos\n",
        "\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score # Métricas"
      ],
      "metadata": {
        "id": "C1SWbdGSjPai"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ## ***Carga de los datos***"
      ],
      "metadata": {
        "id": "OztccPQiOtw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carga de los datos 'spliteados'\n",
        "X_train = sparse.load_npz('./X_train.npz')\n",
        "X_test = sparse.load_npz('./X_test.npz')\n",
        "\n",
        "y_train = pd.read_csv('./y_train.csv')\n",
        "y_test = pd.read_csv('./y_test.csv')\n",
        "\n",
        "# Carga del modelo (regresor logístico)\n",
        "lr = load('./model.joblib')\n",
        "\n",
        "print(X_train.shape), print(X_test.shape), print(y_train.shape), print(y_test.shape), print(lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euahjS92kRWN",
        "outputId": "d5a4a4f1-32c8-4aec-d305-e404befede17"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(63928, 258)\n",
            "(15983, 258)\n",
            "(63928, 1)\n",
            "(15983, 1)\n",
            "LogisticRegression(C=1, max_iter=300, solver='newton-cg')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None, None, None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Métricas**"
      ],
      "metadata": {
        "id": "7W-4rkvt3Hon"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ## ***Cálculo de Métricas***"
      ],
      "metadata": {
        "id": "TzNVTs563Qe7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_predict = lr.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, test_predict)\n",
        "recall = recall_score(y_test, test_predict)\n",
        "precision = precision_score(y_test, test_predict)\n",
        "f1 = f1_score(y_test, test_predict)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'F1 Score: {f1}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYD7QsYPq0Xv",
        "outputId": "e3ecd415-b27e-42c8-cebc-6fa14a7bb064"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7853344178189327\n",
            "Recall: 0.7627582773213841\n",
            "Precision: 0.8007317391872468\n",
            "F1 Score: 0.781283865621215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ## ***Análisis de Métricas***"
      ],
      "metadata": {
        "id": "ltsJcl1X3V_7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un recuento de los resultados obtenidos del modelo de regresión logística que creé:\n",
        "\n",
        "* Precisión (Accuracy): Acierta +/- el 78.5% de las veces al predecir si una opinión es positiva o negativa. Se puede concluír que de manera general es un modelo fiable generalmente.\n",
        "\n",
        "* Ratio de Verdaderos Positivos (Recall): Reconoce +/- el 76.3% cuando son 'verdaderos positivos'. Lo que indica que la gran mayoría de las opiniones son reconocidas por el modelo.\n",
        "\n",
        "* Precisión (Precision): Acierta +/- el 80% de las veces que etiqueta una predicción como\n",
        "'verdaderos positivos'. Lo que indica mucha fiabilidad en identificar las opiniones positivas.\n",
        "\n",
        "* F1 (F1 Score): La combinación de Recall y Precision indica que tiene un porcentaje de aciertos del 78.1% el modelo en indicar correctamente cuándo es un 'verdadero positivo'.\n",
        "\n",
        "Evidentemente no es el mejor modelo, pero se puede decir en sentidos generales es un modelo confiable."
      ],
      "metadata": {
        "id": "9KYrcBrcsGer"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Conclusiones finales y comentarios**\n",
        "\n",
        "En el transcurso de esta práctica, mi pensamiento con el NLP iba cambiando, entendiéndolo mucho más a fondo y agarrándole un gusto que anteriormente no tenía. Afiné bastante mi habilidad con las librerías de pandas y numpy, aprendí demasiadas cosas y algunos trucos de estas dos que no sabía que se podían hacer y fue de increíble ayuda en la práctica. También, pude notar que los modulos anteriores 'machine learning' y 'deep learning' son un pilar importante para hacer más llevadero el aprendizaje de este módulo 'NLP'.\n",
        "\n",
        "Por otro lado hablando del proyecto como tal, se me hizo muy interesante el haber hecho iteraciones en la etapa de preprocesamiento, viendo cómo cambiaban los resultados finales a más profundizaba en el preprocesamiento, el tratar el desbalanceamiento de las clases fue sencillo, aunque me gustaría saber el resultado que tendría donde no lo hubiera hecho.\n",
        "\n",
        "La transformación de la cardinalidad del vocabulario, pre y post-preprocesamiento, me mostró el poder de una limpieza de datos bien ejecutada (y eso que con clara mejoría). Las aproximadas 35 horas invertidas en el desarrollo de esta práctica, aunque intensas, fueron profundamente gratificantes porque no hubo momento de quedarme estancado, no hubo momento de frustración.\n",
        "\n",
        "Por temas de trabajo y otro estudio presencial que estoy haciendo en una universidad de mi país (Colombia), no tuve tiempo de enfrentarme a una red neuronal RNN, cosa que me encantaría hacer en un futuro cercano. Por ahora, ya tengo un \"baseline\" con los dos modelos (bastante robustos) de ML que desarrollé en esta práctica."
      ],
      "metadata": {
        "id": "Q8p-ah4J28Yv"
      }
    }
  ]
}